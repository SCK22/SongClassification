{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X_train_many_features.npy')\n",
    "y = np.load('y_train_many_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split the data\n",
    "#iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct some pipelines\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_lr_pca = Pipeline([('scl', StandardScaler()),\n",
    "('pca', PCA(n_components=2)),\n",
    "('clf', LogisticRegression(random_state=42))])\n",
    "\n",
    "pipe_rf = Pipeline([('scl', StandardScaler()),\n",
    "('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_rf_pca = Pipeline([('scl', StandardScaler()),\n",
    "('pca', PCA(n_components=2)),\n",
    "('clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "pipe_svm = Pipeline([('scl', StandardScaler()),\n",
    "('clf', svm.SVC(random_state=42))])\n",
    "\n",
    "pipe_svm_pca = Pipeline([('scl', StandardScaler()),\n",
    "('pca', PCA(n_components=2)),\n",
    "('clf', svm.SVC(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set grid search params\n",
    "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range_fl = [1.0, 0.5, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_lr = [{'clf__penalty': ['l1', 'l2'],\n",
    "\t\t'clf__C': param_range_fl,\n",
    "\t\t'clf__solver': ['liblinear']}] \n",
    "\n",
    "grid_params_rf = [{'clf__criterion': ['gini', 'entropy'],\n",
    "\t\t'clf__min_samples_leaf': param_range,\n",
    "\t\t'clf__max_depth': param_range,\n",
    "\t\t'clf__min_samples_split': param_range[1:]}]\n",
    "\n",
    "grid_params_svm = [{'clf__kernel': ['linear', 'rbf'], \n",
    "\t\t'clf__C': param_range}]\n",
    "\n",
    "# Construct grid searches\n",
    "jobs = -1\n",
    "\n",
    "gs_lr = GridSearchCV(estimator=pipe_lr,\n",
    "\t\t\tparam_grid=grid_params_lr,\n",
    "\t\t\tscoring='accuracy',\n",
    "\t\t\tcv=10) \n",
    "\t\t\t\n",
    "gs_lr_pca = GridSearchCV(estimator=pipe_lr_pca,\n",
    "\t\t\tparam_grid=grid_params_lr,\n",
    "\t\t\tscoring='accuracy',\n",
    "\t\t\tcv=10)\n",
    "\t\t\t\n",
    "gs_rf = GridSearchCV(estimator=pipe_rf,\n",
    "\t\t\tparam_grid=grid_params_rf,\n",
    "\t\t\tscoring='accuracy',\n",
    "\t\t\tcv=10, \n",
    "\t\t\tn_jobs=jobs)\n",
    "\n",
    "gs_rf_pca = GridSearchCV(estimator=pipe_rf_pca,\n",
    "\t\t\tparam_grid=grid_params_rf,\n",
    "\t\t\tscoring='accuracy',\n",
    "\t\t\tcv=10, \n",
    "\t\t\tn_jobs=jobs)\n",
    "\n",
    "gs_svm = GridSearchCV(estimator=pipe_svm,\n",
    "\t\t\tparam_grid=grid_params_svm,\n",
    "\t\t\tscoring='accuracy',\n",
    "\t\t\tcv=10,\n",
    "\t\t\tn_jobs=jobs)\n",
    "\n",
    "gs_svm_pca = GridSearchCV(estimator=pipe_svm_pca,\n",
    "\t\t\tparam_grid=grid_params_svm,\n",
    "\t\t\tscoring='accuracy',\n",
    "\t\t\tcv=10,\n",
    "\t\t\tn_jobs=jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_lr, gs_lr_pca, gs_rf, gs_rf_pca, gs_svm, gs_svm_pca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'Logistic Regression', 1: 'Logistic Regression w/PCA', \n",
    "\t\t2: 'Random Forest', 3: 'Random Forest w/PCA', \n",
    "\t\t4: 'Support Vector Machine', 5: 'Support Vector Machine w/PCA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Logistic Regression\n",
      "Best params: {'clf__penalty': 'l1', 'clf__C': 1.0, 'clf__solver': 'liblinear'}\n",
      "Best training accuracy: 0.689\n",
      "Test set accuracy score for best params: 0.688 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.57      0.63      0.60       139\n",
      "   classical       0.90      0.96      0.93       142\n",
      "     country       0.73      0.65      0.68       156\n",
      "       disco       0.53      0.51      0.52       137\n",
      "      hiphop       0.65      0.73      0.69       137\n",
      "        jazz       0.72      0.72      0.72       126\n",
      "       metal       0.76      0.88      0.81       126\n",
      "         pop       0.81      0.83      0.82       142\n",
      "      reggae       0.65      0.56      0.60       153\n",
      "        rock       0.52      0.44      0.48       144\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      1402\n",
      "   macro avg       0.68      0.69      0.69      1402\n",
      "weighted avg       0.68      0.69      0.68      1402\n",
      "\n",
      "\n",
      "Estimator: Logistic Regression w/PCA\n",
      "Best params: {'clf__penalty': 'l2', 'clf__C': 1.0, 'clf__solver': 'liblinear'}\n",
      "Best training accuracy: 0.223\n",
      "Test set accuracy score for best params: 0.222 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Best params: {'clf__criterion': 'entropy', 'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2}\n",
      "Best training accuracy: 0.765\n",
      "Test set accuracy score for best params: 0.753 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.72      0.71      0.71       139\n",
      "   classical       0.90      0.91      0.90       142\n",
      "     country       0.71      0.70      0.71       156\n",
      "       disco       0.66      0.60      0.63       137\n",
      "      hiphop       0.73      0.76      0.74       137\n",
      "        jazz       0.68      0.76      0.72       126\n",
      "       metal       0.84      0.84      0.84       126\n",
      "         pop       0.83      0.87      0.85       142\n",
      "      reggae       0.70      0.76      0.73       153\n",
      "        rock       0.77      0.64      0.70       144\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1402\n",
      "   macro avg       0.75      0.75      0.75      1402\n",
      "weighted avg       0.75      0.75      0.75      1402\n",
      "\n",
      "\n",
      "Estimator: Random Forest w/PCA\n",
      "Best params: {'clf__criterion': 'gini', 'clf__max_depth': 9, 'clf__min_samples_leaf': 9, 'clf__min_samples_split': 2}\n",
      "Best training accuracy: 0.269\n",
      "Test set accuracy score for best params: 0.257 \n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Best params: {'clf__C': 10, 'clf__kernel': 'rbf'}\n",
      "Best training accuracy: 0.951\n",
      "Test set accuracy score for best params: 0.956 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       blues       0.89      0.98      0.93       139\n",
      "   classical       0.98      1.00      0.99       142\n",
      "     country       0.94      0.96      0.95       156\n",
      "       disco       0.95      0.93      0.94       137\n",
      "      hiphop       0.97      0.99      0.98       137\n",
      "        jazz       0.98      0.98      0.98       126\n",
      "       metal       0.98      0.95      0.97       126\n",
      "         pop       0.99      0.97      0.98       142\n",
      "      reggae       0.99      0.90      0.94       153\n",
      "        rock       0.89      0.92      0.91       144\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1402\n",
      "   macro avg       0.96      0.96      0.96      1402\n",
      "weighted avg       0.96      0.96      0.96      1402\n",
      "\n",
      "\n",
      "Estimator: Support Vector Machine w/PCA\n",
      "Best params: {'clf__C': 2, 'clf__kernel': 'rbf'}\n",
      "Best training accuracy: 0.270\n",
      "Test set accuracy score for best params: 0.273 \n",
      "\n",
      "Classifier with best test set accuracy: Support Vector Machine\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0127128eaf7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nClassifier with best test set accuracy: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_clf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mMetric_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_clf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                          copy=False)\n\u001b[1;32m    353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\t\n",
    "    # Fit grid search\t\n",
    "    gs.fit(X_train, y_train)\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "    \n",
    "print('\\nClassifier with best test set accuracy: %s' % (grid_dict[best_clf]))\n",
    "Metric_df = pd.DataFrame(grid_dict[best_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best grid search pipeline to file\n",
    "dump_file = 'best_gs_pipeline.pkl'\n",
    "joblib.dump(best_gs, dump_file, compress=1)\n",
    "print('\\nSaved %s grid search pipeline to file: %s' % (grid_dict[best_clf], dump_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "loaded_model = joblib.load('best_gs_pipeline.pkl')\n",
    "result = loaded_model.score(X_test,y_test)\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "viz = ClassificationReport(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = ConfusionMatrix(loaded_model, classes=['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.fit(X_train, y_train,cmp='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = viz.poof() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user yellowbrick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassificationReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('/home/mahidharv/Music/best_gs_pipeline.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
